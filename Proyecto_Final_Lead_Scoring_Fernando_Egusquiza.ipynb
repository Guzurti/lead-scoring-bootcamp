{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bd6581",
   "metadata": {},
   "source": [
    "# Proyecto Final Bootcamp: Análisis de Leads\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "En este notebook se realiza un análisis completo de un dataset de leads con el objetivo de explorar los datos, preparar un modelo de Machine Learning y proponer futuras líneas de investigación.\n",
    "\n",
    "El objetivo principal es predecir la conversión de un lead a cliente a partir de sus características y acciones previas. Para ello, se seguirán los pasos clásicos de la ciencia de datos: exploración, limpieza, modelado, evaluación e interpretación de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa277e19",
   "metadata": {},
   "source": [
    "## 2. Carga y descripción del dataset\n",
    "\n",
    "Se utiliza un dataset ficticio/simulando leads comerciales, preparado para prácticas de aprendizaje. - [Lead Scoring Dataset – Kaggle](https://www.kaggle.com/datasets/amritachatterjee09/lead-scoring-dataset/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4533c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, validation_curve, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay, classification_report, \n",
    "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fece38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/fernandoegusquizamartin/Documents/Código /Proyecto Final/Lead scoring/Data Set Lead Scoring/daraset/Lead Scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801960b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3876df",
   "metadata": {},
   "source": [
    "## 3. Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Vamos a analizar visualmente la distribución de las variables principales y la relación con la conversión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2379a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(data=df, x='Converted')\n",
    "plt.title('Distribución de la variable objetivo: Converted')\n",
    "plt.xlabel('Convertido (1) / No convertido (0)')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['TotalVisits'], kde=True, bins=30)\n",
    "plt.title('Distribución Total de Visitas')\n",
    "plt.xlabel('Total Visits')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b018a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['Total Time Spent on Website'], kde=True, bins=30)\n",
    "plt.title('Distribución de Tiempo Total en la Web')\n",
    "plt.xlabel('Total Time Spent on Website')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['Page Views Per Visit'], kde=True, bins=30)\n",
    "plt.title('Distribución de Page Views Per Visit')\n",
    "plt.xlabel('Page Views Per Visit')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91048f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[np.number])\n",
    "corr = num_cols.corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('Matriz de Correlaciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f40b7",
   "metadata": {},
   "source": [
    "### 3.1. Principales conclusiones del EDA\n",
    "- Hay cierta desbalance en la variable objetivo (`Converted`).\n",
    "- Variables como visitas y tiempo en la web tienen colas largas (outliers).\n",
    "- Algunas variables numéricas están correlacionadas.\n",
    "- Habrá que transformar o tratar algunas variables para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e54b2",
   "metadata": {},
   "source": [
    "## 4. Preparación y limpieza de datos\n",
    "\n",
    "En esta sección:\n",
    "- Eliminamos columnas irrelevantes o con muchos valores únicos (IDs).\n",
    "- Tratamos valores nulos y outliers.\n",
    "- Codificamos variables categóricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimo columnas no informativas y que puedan afectar sobre la predicción de calidad del lead\n",
    "columnas_a_eliminar = [\n",
    "    'Prospect ID',\n",
    "    'Lead Number',\n",
    "    'Receive More Updates About Our Courses',\n",
    "    'Lead Quality',\n",
    "    'Update me on Supply Chain Content',\n",
    "    'I agree to pay the amount through cheque',\n",
    "    'Last Notable Activity',\n",
    "    'A free copy of Mastering The Interview',\n",
    "    'Asymmetrique Profile Score',\n",
    "    'Asymmetrique Activity Score',\n",
    "    'Asymmetrique Activity Index',\n",
    "    'Asymmetrique Profile Index',\n",
    "    'Last Activity',\n",
    "    'Lead Profile',\n",
    "    'Tags'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir valores \"select\" en nulos, para evitar que influyan.\n",
    "df = df.replace(\"Select\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio nulos con la moda\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers: Hago un capado sencillo usando percentiles\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    q_low = df[col].quantile(0.01)\n",
    "    q_hi  = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], q_low, q_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad88971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de variables categóricas (one-hot encoding)\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fd0f8",
   "metadata": {},
   "source": [
    "## 5. Modelado: Random Forest Classifier\n",
    "\n",
    "Entrenamos un modelo básico de Random Forest para predecir la conversión del lead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a287930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Converted', axis=1)\n",
    "y = df['Converted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92750f9e",
   "metadata": {},
   "source": [
    "### 5.1. Importancia de variables\n",
    "Veamos qué variables han sido más relevantes para el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feat_names = X.columns\n",
    "feat_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,5))\n",
    "feat_imp.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 variables más importantes')\n",
    "plt.ylabel('Importancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e7115",
   "metadata": {},
   "source": [
    "### 5.2. Interpretación del modelo con SHAP\n",
    "Explicamos las predicciones usando SHAP para ver el peso de cada variable en la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RandomForestClassifier()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12376412",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(modelo)\n",
    "shap_values = explainer.shap_values(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(shap_values))\n",
    "if isinstance(shap_values, list):\n",
    "    print([v.shape for v in shap_values])\n",
    "else:\n",
    "    print(shap_values.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324acec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:, :, 1], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b04cd4",
   "metadata": {},
   "source": [
    "## 6. Prueba del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ff88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Entrenamos el modelo con todos los datos disponibles\n",
    "X_full = df.drop('Converted', axis=1)\n",
    "y_full = df['Converted']\n",
    "\n",
    "modelo_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_final.fit(X_full, y_full)\n",
    "\n",
    "# 2. Guardamos el modelo entrenado\n",
    "joblib.dump(modelo_final, 'modelo_lead_scoring.pkl')\n",
    "\n",
    "# Guardamos la lista de columnas \n",
    "columnas_modelo = X_full.columns.tolist()\n",
    "joblib.dump(columnas_modelo, 'columnas_modelo.pkl')\n",
    "\n",
    "print(\"Modelo final y columnas guardados correctamente.\")\n",
    "\n",
    "# 3. Función para predecir la probabilidad de conversión de un nuevo lead\n",
    "\n",
    "def predecir_lead(nuevo_lead, modelo, columnas_modelo):\n",
    "    \"\"\"\n",
    "    nuevo_lead: dict con las características del nuevo lead (mismo formato que las columnas originales)\n",
    "    modelo: modelo entrenado\n",
    "    columnas_modelo: lista de columnas que espera el modelo (incluyendo dummies)\n",
    "    \"\"\"\n",
    "    lead_df = pd.DataFrame([nuevo_lead])\n",
    "    lead_df = pd.get_dummies(lead_df)\n",
    "    # Añadir columnas faltantes y ordenar igual que el modelo\n",
    "    for col in columnas_modelo:\n",
    "        if col not in lead_df.columns:\n",
    "            lead_df[col] = 0\n",
    "    lead_df = lead_df[columnas_modelo]\n",
    "    # Predicción\n",
    "    prob = modelo.predict_proba(lead_df)[:, 1][0]\n",
    "    return prob\n",
    "\n",
    "# 4. Ejemplos prácticos de uso\n",
    "\n",
    "# Ejemplo 1: Lead muy interesado (valores altos)\n",
    "nuevo_lead_1 = {\n",
    "    'TotalVisits': 8,\n",
    "    'Total Time Spent on Website': 400,\n",
    "    'Page Views Per Visit': 6,\n",
    "    # ...añade aquí más campos relevantes de tu modelo...\n",
    "    # Incluye las columnas dummies que sean importantes según tu preprocesado\n",
    "}\n",
    "\n",
    "# Ejemplo 2: Lead poco activo (valores bajos)\n",
    "nuevo_lead_2 = {\n",
    "    'TotalVisits': 1,\n",
    "    'Total Time Spent on Website': 50,\n",
    "    'Page Views Per Visit': 1,\n",
    "    # ...añade aquí más campos relevantes de tu modelo...\n",
    "}\n",
    "\n",
    "# Ejemplo 3: Lead sin información en campos clave\n",
    "nuevo_lead_3 = {\n",
    "    'TotalVisits': 2,\n",
    "    'Total Time Spent on Website': 60,\n",
    "    'Page Views Per Visit': 1.5,\n",
    "    # ...campos faltantes se rellenarán como 0 automáticamente...\n",
    "}\n",
    "\n",
    "# Predicción\n",
    "prob1 = predecir_lead(nuevo_lead_1, modelo_final, columnas_modelo)\n",
    "prob2 = predecir_lead(nuevo_lead_2, modelo_final, columnas_modelo)\n",
    "prob3 = predecir_lead(nuevo_lead_3, modelo_final, columnas_modelo)\n",
    "\n",
    "print(f\"Lead 1 - Probabilidad de conversión: {prob1:.2%}\")\n",
    "print(f\"Lead 2 - Probabilidad de conversión: {prob2:.2%}\")\n",
    "print(f\"Lead 3 - Probabilidad de conversión: {prob3:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score\n",
    "\n",
    "# 1. Carga del modelo y las columnas del modelo\n",
    "modelo = joblib.load('modelo_lead_scoring.pkl')\n",
    "columnas_modelo = joblib.load('columnas_modelo.pkl')\n",
    "\n",
    "# 2. Carga del archivo CSV\n",
    "df_nuevos = pd.read_csv('/Users/fernandoegusquizamartin/Documents/Código /Proyecto Final/Lead scoring/Data Set Lead Scoring/daraset/eval_leads.csv')\n",
    "\n",
    "# 3. Preprocesamiento\n",
    "df_nuevos = df_nuevos.replace(\"Select\", np.nan)\n",
    "columnas_a_eliminar = [\n",
    "    'Prospect ID',\n",
    "    'Lead Number',\n",
    "    'Receive More Updates About Our Courses',\n",
    "    'Lead Quality',\n",
    "    'Update me on Supply Chain Content',\n",
    "    'I agree to pay the amount through cheque',\n",
    "    'Last Notable Activity',\n",
    "    'A free copy of Mastering The Interview',\n",
    "    'Asymmetrique Profile Score',\n",
    "    'Asymmetrique Activity Score',\n",
    "    'Asymmetrique Activity Index',\n",
    "    'Asymmetrique Profile Index',\n",
    "    'Last Activity',\n",
    "    'Lead Profile',\n",
    "    'Tags'\n",
    "]\n",
    "converted_original = df_nuevos['Converted'].copy() if 'Converted' in df_nuevos.columns else None\n",
    "\n",
    "df_nuevos = df_nuevos.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "df_nuevos_dummies = pd.get_dummies(df_nuevos)\n",
    "for col in columnas_modelo:\n",
    "    if col not in df_nuevos_dummies.columns:\n",
    "        df_nuevos_dummies[col] = 0\n",
    "df_nuevos_dummies = df_nuevos_dummies[columnas_modelo]\n",
    "\n",
    "# 4. Predicción del modelo (probabilidad y predicción binaria)\n",
    "df_nuevos['Prediccion_Modelo_Prob'] = modelo.predict_proba(df_nuevos_dummies)[:, 1]\n",
    "df_nuevos['Prediccion_Modelo'] = (df_nuevos['Prediccion_Modelo_Prob'] >= 0.5).astype(int)\n",
    "\n",
    "# 5. Comparación con la variable Converted\n",
    "\n",
    "# Limpieza: sólo filas con ambos valores no nulos\n",
    "filtro = ~converted_original.isnull()\n",
    "df_compara = df_nuevos[filtro].copy()\n",
    "df_compara['Converted'] = converted_original[filtro].astype(int)\n",
    "\n",
    "print(df_compara[['Converted', 'Prediccion_Modelo', 'Prediccion_Modelo_Prob']].head())\n",
    "\n",
    "# Matriz de confusión y métricas\n",
    "cm = confusion_matrix(df_compara['Converted'], df_compara['Prediccion_Modelo'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No convertido', 'Convertido'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Matriz de confusión: Converted vs Predicción del modelo')\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(df_compara['Converted'], df_compara['Prediccion_Modelo']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(df_compara['Converted'], df_compara['Prediccion_Modelo_Prob'])\n",
    "print(f'ROC-AUC: {roc_auc:.3f}')\n",
    "\n",
    "# algunos casos donde discrepan\n",
    "print(\"\\nEjemplos donde modelo y real no coinciden:\")\n",
    "print(df_compara[df_compara['Converted'] != df_compara['Prediccion_Modelo']][\n",
    "    ['Converted', 'Prediccion_Modelo', 'Prediccion_Modelo_Prob']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa8c70",
   "metadata": {},
   "source": [
    "El modelo predice correctamente un 67% de los leads. Tiene más aciertos que un modelo aleatorio o uno que siempre prediga la clase mayoritaria. Sin embargo, aún comete algunos errores, sobre todo al predecir algunos leads como ‘convertidos’ que finalmente no lo son. Según el objetivo del negocio, podríamos ajustar el umbral para priorizar no perder oportunidades (recall) o para minimizar falsos positivos (precisión)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga dataset de entrenamiento\n",
    "df = pd.read_csv('/Users/fernandoegusquizamartin/Documents/Código /Proyecto Final/Lead scoring/Data Set Lead Scoring/daraset/Lead Scoring.csv')\n",
    "\n",
    "# Reemplaza valores \"Select\" por nulos\n",
    "df = df.replace(\"Select\", np.nan)\n",
    "\n",
    "# Elimina columnas innecesarias\n",
    "columnas_a_eliminar = [\n",
    "    'Prospect ID', 'Lead Number', 'Receive More Updates About Our Courses', 'Lead Quality',\n",
    "    'Update me on Supply Chain Content', 'I agree to pay the amount through cheque',\n",
    "    'Last Notable Activity', 'A free copy of Mastering The Interview',\n",
    "    'Asymmetrique Profile Score', 'Asymmetrique Activity Score', 'Asymmetrique Activity Index',\n",
    "    'Asymmetrique Profile Index', 'Last Activity', 'Lead Profile', 'Tags'\n",
    "]\n",
    "df = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "# Opcional: Rellenar nulos (puedes personalizar esto según tu criterio)\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Convertir variables categóricas a dummies\n",
    "X = df.drop('Converted', axis=1)\n",
    "y = df['Converted']\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Guarda las columnas para futuros datos de test\n",
    "columnas_modelo = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf465283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_probs = rf.predict_proba(X_test)[:,1]\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"Random Forest ROC-AUC: \", roc_auc_score(y_test, rf_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0554ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_probs = xgb_model.predict_proba(X_test)[:,1]\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, xgb_pred))\n",
    "print(\"XGBoost ROC-AUC: \", roc_auc_score(y_test, xgb_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadae3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_pr(y_test, probs, modelo_name):\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    auc_score = roc_auc_score(y_test, probs)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.title(f'Curva ROC - {modelo_name}')\n",
    "    plt.xlabel('Tasa de falsos positivos')\n",
    "    plt.ylabel('Tasa de verdaderos positivos')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # PR\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "    avg_precision = average_precision_score(y_test, probs)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f'PR curve (AP = {avg_precision:.2f})')\n",
    "    plt.title(f'Curva Precision-Recall - {modelo_name}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_pr(y_test, rf_probs, \"Random Forest\")\n",
    "plot_roc_pr(y_test, xgb_probs, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = [10, 50, 100, 200, 300]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    X, y, param_name=\"n_estimators\", param_range=param_range,\n",
    "    cv=3, scoring=\"roc_auc\"\n",
    ")\n",
    "plt.figure()\n",
    "plt.plot(param_range, test_scores.mean(axis=1), label='Test ROC-AUC')\n",
    "plt.plot(param_range, train_scores.mean(axis=1), label='Train ROC-AUC')\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "plt.title(\"Curva de validación - Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0618a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid, cv=3, scoring='roc_auc'\n",
    ")\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(\"Mejores parámetros XGBoost:\", grid_xgb.best_params_)\n",
    "print(\"Mejor ROC-AUC (CV):\", grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score\n",
    "\n",
    "df_nuevos = pd.read_csv('/Users/fernandoegusquizamartin/Documents/Código /Proyecto Final/Lead scoring/Data Set Lead Scoring/daraset/eval_leads.csv')\n",
    "df_nuevos = df_nuevos.replace(\"Select\", np.nan)\n",
    "\n",
    "columnas_a_eliminar = [\n",
    "    'Prospect ID', 'Lead Number', 'Receive More Updates About Our Courses', 'Lead Quality',\n",
    "    'Update me on Supply Chain Content', 'I agree to pay the amount through cheque',\n",
    "    'Last Notable Activity', 'A free copy of Mastering The Interview',\n",
    "    'Asymmetrique Profile Score', 'Asymmetrique Activity Score', 'Asymmetrique Activity Index',\n",
    "    'Asymmetrique Profile Index', 'Last Activity', 'Lead Profile', 'Tags'\n",
    "]\n",
    "converted_original = df_nuevos['Converted'].copy() if 'Converted' in df_nuevos.columns else None\n",
    "\n",
    "df_nuevos = df_nuevos.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "df_nuevos_dummies = pd.get_dummies(df_nuevos)\n",
    "\n",
    "for col in columnas_modelo:\n",
    "    if col not in df_nuevos_dummies.columns:\n",
    "        df_nuevos_dummies[col] = 0\n",
    "df_nuevos_dummies = df_nuevos_dummies[columnas_modelo]\n",
    "\n",
    "# 1. Predicción con Random Forest\n",
    "df_nuevos['RF_Prob'] = rf.predict_proba(df_nuevos_dummies)[:, 1]\n",
    "df_nuevos['RF_Pred'] = (df_nuevos['RF_Prob'] >= 0.5).astype(int)\n",
    "\n",
    "# 2. Predicción con XGBoost\n",
    "df_nuevos['XGB_Prob'] = xgb_model.predict_proba(df_nuevos_dummies)[:, 1]\n",
    "df_nuevos['XGB_Pred'] = (df_nuevos['XGB_Prob'] >= 0.5).astype(int)\n",
    "\n",
    "# 3. Comparación con variable real\n",
    "filtro = ~converted_original.isnull()\n",
    "df_compara = df_nuevos[filtro].copy()\n",
    "df_compara['Converted'] = converted_original[filtro].astype(int)\n",
    "\n",
    "print(\"\\nHEAD de resultados comparativos:\")\n",
    "print(df_compara[['Converted', 'RF_Pred', 'RF_Prob', 'XGB_Pred', 'XGB_Prob']].head())\n",
    "\n",
    "# 4. Métricas y matriz de confusión\n",
    "for modelo, pred_col, prob_col, nombre in [\n",
    "    (rf, 'RF_Pred', 'RF_Prob', 'Random Forest'),\n",
    "    (xgb_model, 'XGB_Pred', 'XGB_Prob', 'XGBoost')\n",
    "]:\n",
    "    print(f\"\\n--- {nombre} ---\")\n",
    "    cm = confusion_matrix(df_compara['Converted'], df_compara[pred_col])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No convertido', 'Convertido'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f'Matriz de confusión: Converted vs {nombre}')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(df_compara['Converted'], df_compara[pred_col]))\n",
    "    roc_auc = roc_auc_score(df_compara['Converted'], df_compara[prob_col])\n",
    "    print(f'{nombre} ROC-AUC: {roc_auc:.3f}')\n",
    "\n",
    "    print(\"\\nEjemplos donde modelo y real no coinciden:\")\n",
    "    print(df_compara[df_compara['Converted'] != df_compara[pred_col]][\n",
    "        ['Converted', pred_col, prob_col]].head(10))\n",
    "\n",
    "# 5. Curvas ROC y PR\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score\n",
    "\n",
    "# ROC\n",
    "for prob_col, nombre in [('RF_Prob', 'Random Forest'), ('XGB_Prob', 'XGBoost')]:\n",
    "    fpr, tpr, _ = roc_curve(df_compara['Converted'], df_compara[prob_col])\n",
    "    auc = roc_auc_score(df_compara['Converted'], df_compara[prob_col])\n",
    "    plt.plot(fpr, tpr, label=f\"{nombre} (AUC={auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"Curva ROC - eval_leads.csv\")\n",
    "plt.xlabel(\"Falsos positivos\")\n",
    "plt.ylabel(\"Verdaderos positivos\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# PR\n",
    "for prob_col, nombre in [('RF_Prob', 'Random Forest'), ('XGB_Prob', 'XGBoost')]:\n",
    "    precision, recall, _ = precision_recall_curve(df_compara['Converted'], df_compara[prob_col])\n",
    "    ap = average_precision_score(df_compara['Converted'], df_compara[prob_col])\n",
    "    plt.plot(recall, precision, label=f\"{nombre} (AP={ap:.2f})\")\n",
    "plt.title(\"Curva Precision-Recall - eval_leads.csv\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- Tuneo para Random Forest ---\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"Mejores parámetros Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Mejor ROC-AUC (CV) Random Forest:\", grid_rf.best_score_)\n",
    "\n",
    "# --- Tuneo para XGBoost ---\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 1],\n",
    "    'colsample_bytree': [0.7, 1],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid_xgb,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(\"Mejores parámetros XGBoost:\", grid_xgb.best_params_)\n",
    "print(\"Mejor ROC-AUC (CV) XGBoost:\", grid_xgb.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b06e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Split de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Balanceo con SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "print(\"Distribución tras SMOTE:\", y_train_bal.value_counts())\n",
    "\n",
    "# 3. Entrenamiento de modelos balanceados\n",
    "\n",
    "# Random Forest con class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_bal = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# XGBoost con scale_pos_weight\n",
    "import xgboost as xgb\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "xgb_bal = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "xgb_bal.fit(X_train_bal, y_train_bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7af456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesado de eval_leads.csv \n",
    "df_nuevos = pd.read_csv('/Users/fernandoegusquizamartin/Documents/Código /Proyecto Final/Lead scoring/Data Set Lead Scoring/daraset/eval_leads.csv')\n",
    "df_nuevos = df_nuevos.replace(\"Select\", np.nan)\n",
    "columnas_a_eliminar = [\n",
    "    'Prospect ID', 'Lead Number', 'Receive More Updates About Our Courses', 'Lead Quality',\n",
    "    'Update me on Supply Chain Content', 'I agree to pay the amount through cheque',\n",
    "    'Last Notable Activity', 'A free copy of Mastering The Interview',\n",
    "    'Asymmetrique Profile Score', 'Asymmetrique Activity Score', 'Asymmetrique Activity Index',\n",
    "    'Asymmetrique Profile Index', 'Last Activity', 'Lead Profile', 'Tags'\n",
    "]\n",
    "converted_original = df_nuevos['Converted'].copy() if 'Converted' in df_nuevos.columns else None\n",
    "\n",
    "df_nuevos = df_nuevos.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "df_nuevos_dummies = pd.get_dummies(df_nuevos)\n",
    "for col in columnas_modelo:\n",
    "    if col not in df_nuevos_dummies.columns:\n",
    "        df_nuevos_dummies[col] = 0\n",
    "df_nuevos_dummies = df_nuevos_dummies[columnas_modelo]\n",
    "\n",
    "# Predicción con modelos balanceados\n",
    "df_nuevos['RF_Bal_Prob'] = rf_bal.predict_proba(df_nuevos_dummies)[:, 1]\n",
    "df_nuevos['RF_Bal_Pred'] = (df_nuevos['RF_Bal_Prob'] >= 0.5).astype(int)\n",
    "\n",
    "df_nuevos['XGB_Bal_Prob'] = xgb_bal.predict_proba(df_nuevos_dummies)[:, 1]\n",
    "df_nuevos['XGB_Bal_Pred'] = (df_nuevos['XGB_Bal_Prob'] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación con la variable real\n",
    "filtro = ~converted_original.isnull()\n",
    "df_compara = df_nuevos[filtro].copy()\n",
    "df_compara['Converted'] = converted_original[filtro].astype(int)\n",
    "\n",
    "print(\"\\nHEAD de resultados comparativos (balanceados):\")\n",
    "print(df_compara[['Converted', 'RF_Bal_Pred', 'RF_Bal_Prob', 'XGB_Bal_Pred', 'XGB_Bal_Prob']].head())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for modelo, pred_col, prob_col, nombre in [\n",
    "    (rf_bal, 'RF_Bal_Pred', 'RF_Bal_Prob', 'Random Forest Balanceado'),\n",
    "    (xgb_bal, 'XGB_Bal_Pred', 'XGB_Bal_Prob', 'XGBoost Balanceado')\n",
    "]:\n",
    "    print(f\"\\n--- {nombre} ---\")\n",
    "    cm = confusion_matrix(df_compara['Converted'], df_compara[pred_col])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No convertido', 'Convertido'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f'Matriz de confusión: Converted vs {nombre}')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(df_compara['Converted'], df_compara[pred_col]))\n",
    "    roc_auc = roc_auc_score(df_compara['Converted'], df_compara[prob_col])\n",
    "    print(f'{nombre} ROC-AUC: {roc_auc:.3f}')\n",
    "\n",
    "    print(\"\\nEjemplos donde modelo y real no coinciden:\")\n",
    "    print(df_compara[df_compara['Converted'] != df_compara[pred_col]][\n",
    "        ['Converted', pred_col, prob_col]].head(10))\n",
    "\n",
    "# Curvas ROC y PR\n",
    "# ROC\n",
    "for prob_col, nombre in [('RF_Bal_Prob', 'Random Forest Balanceado'), ('XGB_Bal_Prob', 'XGBoost Balanceado')]:\n",
    "    fpr, tpr, _ = roc_curve(df_compara['Converted'], df_compara[prob_col])\n",
    "    auc = roc_auc_score(df_compara['Converted'], df_compara[prob_col])\n",
    "    plt.plot(fpr, tpr, label=f\"{nombre} (AUC={auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"Curva ROC - Modelos Balanceados (eval_leads.csv)\")\n",
    "plt.xlabel(\"Falsos positivos\")\n",
    "plt.ylabel(\"Verdaderos positivos\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# PR\n",
    "for prob_col, nombre in [('RF_Bal_Prob', 'Random Forest Balanceado'), ('XGB_Bal_Prob', 'XGBoost Balanceado')]:\n",
    "    precision, recall, _ = precision_recall_curve(df_compara['Converted'], df_compara[prob_col])\n",
    "    ap = average_precision_score(df_compara['Converted'], df_compara[prob_col])\n",
    "    plt.plot(recall, precision, label=f\"{nombre} (AP={ap:.2f})\")\n",
    "plt.title(\"Curva Precision-Recall - Modelos Balanceados (eval_leads.csv)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "umbrales = np.linspace(0, 1, 1000)\n",
    "falsos_positivos = []\n",
    "mejor_umbral = 1.0  \n",
    "\n",
    "for umbral in umbrales:\n",
    "    pred = (probs >= umbral).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    falsos_positivos.append(fp)\n",
    "    if fp == 0:\n",
    "        mejor_umbral = umbral\n",
    "        break  \n",
    "\n",
    "print(f\"Umbral mínimo para 0 falsos positivos: {mejor_umbral:.3f}\")\n",
    "\n",
    "\n",
    "pred_0_fp = (probs >= mejor_umbral).astype(int)\n",
    "print(confusion_matrix(y_test, pred_0_fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = xgb_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ecc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "umbrales = np.linspace(0, 1, 1000)\n",
    "falsos_positivos = []\n",
    "mejor_umbral = 1.0  \n",
    "\n",
    "for umbral in umbrales:\n",
    "    pred = (probs >= umbral).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    falsos_positivos.append(fp)\n",
    "    if fp == 0:\n",
    "        mejor_umbral = umbral\n",
    "        break  \n",
    "\n",
    "print(f\"Umbral mínimo para 0 falsos positivos: {mejor_umbral:.3f}\")\n",
    "\n",
    "\n",
    "pred_0_fp = (probs >= mejor_umbral).astype(int)\n",
    "print(confusion_matrix(y_test, pred_0_fp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
